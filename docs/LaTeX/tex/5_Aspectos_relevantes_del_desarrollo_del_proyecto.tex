\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

\section{Inicio del proyecto}

El desarrollo de este proyecto surgió tras un proceso de negociación y diálogo con mi tutor, 
durante el cual le presenté varias propuestas iniciales. A partir de sus ideas y sugerencias, 
acordamos centrar el trabajo en la creación de un sistema para la corrección automática de 
tareas de alumnos utilizando inteligencia artificial.

La motivación principal radica en la creciente integración de tecnologías de inteligencia artificial 
y modelos de lenguaje a gran escala (\textit{LLMs}) en el ámbito educativo. Dado que el alumnado empieza a 
ayudarse de la guía proporcionada por este tipo de herramientas en la resolución de sus tareas, 
resulta natural y necesario explorar métodos que permitan 
evaluar dichas tareas utilizando la misma metodología basada en \textit{IA}.

El proyecto se seleccionó por ser una propuesta innovadora, que aprovecha tecnologías actuales 
como los \textit{LLMs} para implementar una aplicación web que se distingue de las soluciones tradicionales 
de corrección automática. Esta aplicación no solo integra inteligencia artificial generativa, sino que 
también ofrece una interfaz y funcionalidades diferentes a lo habitual, adaptándose a las necesidades 
actuales del entorno educativo digital.

Este enfoque no solo pretende agilizar el proceso de evaluación, sino también adaptarse a las nuevas 
formas de aprendizaje y producción de contenidos, manteniendo la coherencia con las herramientas que 
los alumnos emplean. De esta forma, el proyecto se posiciona como una respuesta innovadora y pertinente 
a la evolución tecnológica en el contexto académico.

\section{Gestión y metodología del proyecto}

Desde el inicio del proyecto se decidió aplicar una \textbf{metodología ágil} adaptada al contexto académico e individual del trabajo. 
En concreto, se optó por \textbf{\textit{Scrumban}}~\cite{web:scrumban}, una combinación entre \textit{Scrum} y \textit{Kanban} que permite mantener ciclos de trabajo planificados 
(\textit{sprints}) al mismo tiempo que se ofrece una mayor flexibilidad en la gestión de tareas.

El proyecto se estructuró en \textit{sprints} de dos semanas, al final de los cuales se realizaban \textbf{reuniones con el tutor}. 
En estas sesiones se revisaban las \textbf{tareas completadas} durante el \textit{sprint} anterior, 
se evaluaba el cumplimiento de los objetivos y se proponían nuevas tareas para el siguiente ciclo. 
Este enfoque iterativo facilitó una \textbf{mejora continua} del producto y permitió adaptarse a cambios o mejoras surgidas a lo largo del desarrollo.

La \textbf{gestión de tareas} se realizó con la herramienta \textbf{\emph{Zube}}, integrada con \textit{GitHub}. Esta plataforma permitió organizar el trabajo mediante 
\textit{issues}, que simulaban la dinámica de un equipo multidisciplinar. Se utilizó un \textbf{tablero \emph{Kanban}} con columnas como 
\textit{inbox}, \textit{ready}, \textit{in progress}, \textit{in review} y \textit{done}, lo que ayudó a tener una visión clara y actualizada del estado de cada tarea y a 
gestionar eficazmente el flujo de trabajo.

También se utilizaron \textbf{gráficos \textit{burndown}} para medir el progreso de cada \textit{sprint} y visualizar la carga de trabajo restante. 
En general, se logró cumplir con los plazos previstos. Estas herramientas resultaron útiles para mantener un \textbf{control claro del avance} y asegurar que los objetivos establecidos al inicio de cada ciclo se cumplieran de forma efectiva.

Adicionalmente, para el \textbf{control de versiones} se siguió la \textbf{metodología \textit{GitFlow}}, que permitió organizar el repositorio de forma estructurada 
mediante ramas diferenciadas como \textit{main}, \textit{develop}, \textit{feature}, \textit{release} y \textit{hotfix}. Esta estrategia facilitó un desarrollo más limpio, 
con mayor trazabilidad de los cambios y mejor manejo de nuevas funcionalidades y correcciones de errores.

\section{Formación}

Este trabajo ha requerido adquirir ciertos conocimientos específicos que inicialmente no se dominaban en profundidad, especialmente en lo relativo a la integración de modelos de lenguaje (\textit{LLMs}) con aplicaciones web, la ejecución de tareas en segundo plano y el despliegue de servicios mediante contenedores. No obstante, ya se contaba con una base previa en bases de datos y programación en Python, lo cual ha facilitado algunas de las fases del proyecto.

La tecnología central del \textit{backend} ha sido el \textit{framework Django}, cuyo sistema de vistas, \textit{ORM} y gestión de rutas se ha aprendido principalmente a través de su documentación oficial~\cite{web:django,web:django-orm}, y mediante pruebas experimentales con pequeños proyectos de ejemplo. La comprensión de los distintos motores de bases de datos también fue necesaria; se optó finalmente por \textit{PostgreSQL} como solución~\cite{web:postgresql}.

Uno de los mayores retos ha sido la integración de modelos de lenguaje ejecutados localmente a través de \textit{Ollama}~\cite{web:ollama}. Para ello, fue clave familiarizarse con el funcionamiento de la biblioteca \textit{LangChain}~\cite{web:langchain}, así como su extensión para \textit{Ollama}~\cite{web:langchain-ollama}.

En cuanto a la ejecución de tareas en segundo plano, fundamental para no bloquear la experiencia del usuario, se investigaron varias alternativas. Finalmente se eligió \texttt{Celery} con \texttt{Redis} como broker~\cite{web:celery,web:redis}.

Otro aspecto relevante del aprendizaje ha sido la contenerización de servicios mediante \textit{Docker} y \textit{Docker Compose}, lo cual permitió simular entornos de producción de forma local. Aunque no se tenía experiencia previa con estas tecnologías, su curva de aprendizaje fue razonable gracias a su documentación oficial y a la gran cantidad de recursos disponibles en línea~\cite{web:docker_doc}.

En cuanto al desarrollo del \textit{frontend}, se utilizaron conocimientos previos de \texttt{HTML}~\cite{web:html}, \texttt{CSS}~\cite{web:css} y \texttt{JavaScript}~\cite{web:javascript}, complementados con el uso del framework \texttt{Tailwind CSS}~\cite{web:tailwind} y su librería de componentes Flowbite~\cite{web:flowbite}, que permitieron construir una interfaz moderna y accesible.

Por último, para la documentación técnica del proyecto se exploraron y probaron herramientas como Sphinx~\cite{web:sphinx}, su tema Book Theme~\cite{web:sphinxbooktheme} y MkDocs~\cite{web:mkdocs}. También se utilizó Markdown~\cite{web:markdown} como lenguaje de marcado ligero y herramientas visuales como Draw.io~\cite{web:drawio} y Miro~\cite{web:miro} para la elaboración de diagramas y esquemas.

A lo largo del proceso se han consultado otras muchas fuentes, tanto en forma de documentación como de vídeos~\cite{web:django-curso-youtube,web:django-curso-youtube-pildoras} y artículos técnicos, pero sin duda las anteriormente mencionadas han sido las más relevantes en cuanto a la formación adquirida durante el desarrollo de este proyecto.

\section{Desarrollo de la aplicación}

El desarrollo de la aplicación se estructuró en fases iterativas, comenzando con la implementación de las funcionalidades básicas de gestión de usuarios y navegación. La primera etapa incluyó el desarrollo del sistema de autenticación (\textit{login, logout} y registro), así como la creación de una página inicial sencilla desde la cual los usuarios podían acceder al resto de funcionalidades. Esta base permitió asegurar un entorno seguro y personalizado para cada usuario.

Posteriormente, se incorporaron las funcionalidades relacionadas con la gestión de los elementos fundamentales para la evaluación: los \textit{prompts} y las rúbricas. Se implementaron las funcionalidades necesarias para crear, consultar y eliminar prompts personalizados, así como importar rúbricas de evaluación en formato markdown, con el objetivo de facilitar la configuración de criterios de corrección.

En una siguiente iteración, se desarrolló la lógica para configurar las correcciones propiamente dichas. En esta fase, la aplicación permitió asociar un \textit{prompt}, una rúbrica y subir un fichero comprimido con las tareas de programación ubicadas en la raíz del fichero. Estas configuraciones quedaban almacenadas en la base de datos, permitiendo mantener un registro estructurado de cada tarea de evaluación preparada por el usuario.

Con la configuración establecida, se implementó el procesamiento en segundo plano de las correcciones utilizando \texttt{Celery} junto con \texttt{Redis} como \textit{message broker}. Esta solución permitió ejecutar de forma asíncrona las tareas relacionadas con el envío de información al modelo de lenguaje y la recepción de respuestas, evitando bloquear el servidor principal.

Debido a que los \textit{LLMs} pueden tardar varios segundos en generar una respuesta, especialmente en entornos locales, resultaba inviable gestionar estas operaciones de forma síncrona. Gracias a esta arquitectura, la aplicación mantiene su capacidad de respuesta y permite gestionar múltiples evaluaciones simultáneamente sin afectar al rendimiento general.

Finalmente, se añadió la posibilidad de modificar ciertos parámetros del modelo \textit{LLM} en cada evaluación, como el nivel de creatividad (\textit{temperatura}), la probabilidad acumulada máxima (\textit{top-p}) y el número máximo de \textit{tokens} considerados en la selección (\textit{top-k}). Esta flexibilidad permitió a los usuarios adaptar la evaluación a distintos escenarios y necesidades específicas.

\subsection*{Procesamiento de archivos y estructura del sistema}

Se estableció un sistema de subida de archivos donde el usuario podía cargar:
\begin{itemize}
    \item Un archivo con la rúbrica de evaluación (en formato \texttt{md}).
    \item Un archivo comprimido con las tareas en su interior.
\end{itemize}

Además, el usuario podía escribir manualmente un \textit{prompt} personalizado. La lógica del sistema se encargaba de ensamblar todos estos elementos en una única entrada textual coherente, que era enviada al modelo.

\subsection*{Evaluación con modelos LLM}

El modelo principal utilizado fue \texttt{LLaMA 3.1}, ejecutado localmente a través de \textit{Ollama} e integrado en la lógica de la aplicación mediante la librería \texttt{langchain-ollama}.

Cada evaluación se procesaba como una tarea independiente, registrando:
\begin{itemize}
    \item Fecha y hora de la configuración.
    \item \textit{Prompt} y rúbrica utilizados.
    \item Tareas evaluadas.
    \item Fecha y hora de la evaluación.
    \item Parámetros del modelo y formato de la respuesta.
    \item Respuesta devuelta por el modelo.
\end{itemize}

Cada evaluación generaba un archivo de texto plano (\texttt{.txt}) que se almacenaba en el directorio \texttt{media}.

\subsection*{Interfaz y usabilidad}

La interfaz web fue desarrollada con \texttt{HTML}, \texttt{CSS} y \texttt{JavaScript}, apoyada por \texttt{Tailwind CSS} y la biblioteca de componentes \texttt{Flowbite}, lo que permitió un diseño limpio y funcional. Se priorizó una navegación simple en la que el flujo de trabajo fuera evidente: autenticación → gestión de prompts  → gestión de rúbricas → configuración de evaluación → ejecución de correcciones → consulta o descarga de resultado.

Se incorporaron funcionalidades adicionales como:
\begin{itemize}
    \item Tabla de correcciones por usuario.
    \item Tabla de rúbricas por usuario.
    \item Tabla de prompts por usuario.
    \item Gestión de usuarios y sesiones mediante el sistema de autenticación de Django.
\end{itemize}

\subsection*{Contenerización y despliegue}

Para garantizar la reproducibilidad y facilitar el despliegue en distintos entornos, se optó por contenerizar todos los servicios mediante \texttt{Docker}. El sistema quedó estructurado en varios contenedores:
\begin{itemize}
    \item \textit{Django}.
    \item Base de datos \textit{PostgreSQL}.
    \item \textit{Broker} de mensajería \textit{Redis}.
    \item \textit{Ollama} con modelos \textit{LLM}.
    \item \textit{Celery}.
\end{itemize}

Esta separación de servicios permitió trabajar de forma más ordenada y facilitó el proceso de pruebas y desarrollo local.

\subsection*{Resumen de funcionalidades desarrolladas}

A lo largo del desarrollo se implementaron las siguientes características clave:

\begin{itemize}
    \item Sistema de autenticación con \textit{login, logout} y registro.
    \item Gestión y edición de \textit{prompts} y rúbricas.
    \item Configuración de tareas de evaluación que almacenan \textit{prompt}, rúbrica y archivos asociados.
    \item Ejecución asincrónica de evaluaciones mediante Celery y Redis.
    \item Personalización de parámetros del modelo \textit{LLM} en cada evaluación.
    \item Registro, almacenamiento y consulta de resultados.
    \item Interfaz web amigable y funcional.
    \item Contenerización completa para facilitar el despliegue.
\end{itemize}

El desarrollo modular y progresivo permitió construir una aplicación fácilmente ampliable, alineada con los objetivos establecidos al inicio del proyecto.

\subsection{Constantes configurables del sistema}

El sistema cuenta con ciertas constantes definidas en el código fuente que permiten ajustar su comportamiento de forma sencilla. En particular, existen dos elementos clave que pueden modificarse para ampliar la funcionalidad de la aplicación:

\begin{itemize}
    \item En el archivo \texttt{corrections/views.py}, línea 28, se encuentra la tupla \texttt{VALID\_EXTENSION}, que especifica las extensiones de archivo válidas para la corrección automática. Actualmente incluye formatos como \texttt{.java}, \texttt{.sql}, \texttt{.py}, \texttt{.cpp}, \texttt{.txt}, entre otros. Esta lista puede ampliarse fácilmente para soportar nuevos lenguajes o tipos de archivo.
    
    \item En el archivo \texttt{corrections/forms.py}, línea 10, se define la lista \texttt{MODEL\_CONTEXT\_CHOICES}, que establece las opciones de contexto máximo en número de \textit{tokens} que pueden procesarse por el modelo de lenguaje. Los valores actuales son 2048, 4096 y 8192 \textit{tokens}, pero esta lista puede modificarse para incorporar futuras configuraciones.
\end{itemize}

Estas constantes permiten adaptar la aplicación a distintos entornos o requerimientos sin necesidad de modificar la lógica principal del sistema.


\section{Problemas, incidencias y soluciones}

Durante el desarrollo de la aplicación surgieron distintos problemas técnicos, principalmente relacionados con la ejecución de tareas asíncronas mediante \texttt{Celery} y la contenerización del proyecto con \texttt{Docker}. A continuación, se describen los problemas más relevantes y las soluciones aplicadas.

\subsection*{Inicio con \texttt{async} de \textit{Django} y cambio a \texttt{Celery} y \texttt{Redis}}

En una primera etapa, se intentó utilizar las funcionalidades \texttt{async} nativas de \textit{Django} para gestionar la ejecución de tareas en segundo plano. Sin embargo, esta implementación inicial no cumplía con las necesidades reales de procesamiento asíncrono, ya que no permitía la ejecución fuera del ciclo de vida de la solicitud \textit{HTTP} ni garantizaba la persistencia ni la gestión eficiente de tareas largas.

\textbf{Solución:} Se optó por integrar \texttt{Celery} como sistema de cola de tareas junto con \texttt{Redis} como broker de mensajes. Esta combinación permitió una gestión robusta y confiable de las tareas asíncronas, garantizando que las operaciones de evaluación y generación de respuestas pudieran ejecutarse en segundo plano sin afectar la experiencia del usuario.

\subsection*{Advertencia por ejecutar Celery como usuario \texttt{root}}

Uno de los primeros problemas detectados fue una advertencia al iniciar \texttt{Celery}, que alertaba de que el proceso se estaba ejecutando como usuario \texttt{root}. Aunque funcional, esto supone un riesgo potencial de seguridad, especialmente en entornos de producción, y va en contra de las buenas prácticas recomendadas.

\textbf{Solución:} Para evitar ejecutar procesos como superusuario, se creó un nuevo usuario dentro del contenedor de Docker (llamado \texttt{dj\_admin}) y se configuró para que los procesos de Django y Celery se ejecutaran bajo ese usuario. En el archivo \texttt{Dockerfile}, se utilizó la instrucción \texttt{USER dj\_admin} para establecer este comportamiento. Esto permitió mantener un entorno más seguro y alineado con las recomendaciones de los \textit{frameworks} utilizados.

\subsection*{Problemas de permisos al escribir en la carpeta \texttt{media}}

Tras aplicar la solución anterior, surgió una nueva incidencia: el usuario \texttt{dj\_admin} no tenía permisos suficientes para acceder a la carpeta \texttt{media}, que se utiliza para almacenar archivos temporales y resultados de las evaluaciones (en formato \texttt{.txt}). Esta carpeta es esencial para el correcto funcionamiento del sistema, ya que en ella se guardan las tareas a corregir, así como la respuesta generada por el modelo \textit{LLM}.

\textbf{Solución:} Se añadieron comandos específicos al \texttt{Dockerfile} para asignar los permisos adecuados a la carpeta \texttt{/app/media}. Concretamente, se utilizó el siguiente bloque de instrucciones:

\begin{verbatim}
...

RUN chown -R dj_admin:dj_admin /app/media

EXPOSE 8000

COPY entrypoint.sh /entrypoint.sh

RUN chmod +x /entrypoint.sh

ENTRYPOINT ["/entrypoint.sh"]

USER dj_admin

CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]

\end{verbatim}

Esto garantiza que el usuario sin privilegios tenga acceso completo a dicha carpeta. Con este ajuste, fue posible evitar errores de acceso y escritura al ejecutar tareas de evaluación que involucran la generación y almacenamiento de archivos.

\subsection*{Conflictos por carpetas \texttt{media} durante la ejecución de tests}

Durante la ejecución de los \textit{tests} automatizados de la aplicación de correcciones, se detectó que se creaban carpetas nuevas dentro del directorio \texttt{media}. Esto podía provocar interferencias o conflictos con datos y archivos pertenecientes a otros usuarios, afectando la integridad y el aislamiento de las pruebas.

\textbf{Solución:} Para evitar estos problemas, se implementó un mecanismo que crea una carpeta temporal específica para \texttt{media} cada vez que se ejecutan los \textit{tests}. Esta carpeta temporal se utiliza exclusivamente durante la ejecución de las pruebas y se elimina automáticamente al finalizar, garantizando así que el entorno de \textit{tests} esté aislado y no interfiera con el sistema en uso normal.

Esta estrategia asegura un entorno limpio y reproducible para las pruebas, mejorando la fiabilidad y evitando efectos colaterales no deseados en el almacenamiento de archivos durante la fase de \textit{testing}.
