\capitulo{3}{Conceptos teóricos}


\section{Procesamiento de lenguaje natural (NLP)}

El procesamiento del lenguaje natural (NLP) es un campo de la inteligencia artificial centrado en 
la interacción entre las computadoras y el lenguaje humano que permite a los ordenadores entender, 
interpretar y trabajar con este lenguaje de forma eficaz. Esta tecnología es esencial para 
analizar información escrita o hablada, superando desafíos como las variaciones en los dialectos, 
el uso de jerga o las irregularidades gramaticales propias del lenguaje cotidiano.


A lo largo de la historia, el lenguaje natural ha evolucionado desde los primeros sistemas de 
procesamiento de texto hasta los modelos avanzados de hoy en día.

En sus inicios, el procesamiento del lenguaje natural se centraba en reglas gramaticales 
catalogando reglas sintácticas y semánticas que aumentaban en complejidad con el tiempo, 
resultando difíciles de mantener. Estos sistemas eran limitados y no podían adaptarse a la 
diversidad del lenguaje humano.

Con el tiempo, se introdujeron enfoques estadísticos basados en modelos probabilísticos que 
utilizaban grandes cantidades de datos para aprender patrones en el lenguaje. 

La siguiente etapa fue la llegada de los modelos de aprendizaje profundo \textit{deep learning}, 
que revolucionaron el campo al permitir la creación de representaciones vectoriales del lenguaje. 
Estos modelos, como las redes neuronales recurrentes (RNN) y las redes neuronales convolucionales 
(CNN), mejoraron significativamente la precisión en tareas como la traducción automática y el 
análisis de sentimientos.

El avance más reciente ha sido el desarrollo de la arquitectura Transformer. Esta tecnología 
reemplazó a las RNN tradicionales gracias a su uso del mecanismo de atención, que permite procesar
 secuencias de texto de manera más eficiente y con mayor contexto. Los Transformers emplean 
 componentes llamados \textit{encoders} y \textit{decoders} para transformar entradas en salidas, y 
 son la base de los modelos de lenguaje más avanzados utilizados actualmente, como GPT, BERT o T5.

\section{Modelos de lenguaje grandes (LLM)}




\section{Secciones}

Las secciones se incluyen con el comando section.

\subsubsection{Subsubsecciones}

Y subsecciones. 


\section{Referencias}

Las referencias se incluyen en el texto usando cite~\cite{wiki:latex}. Para citar webs, artículos o libros~\cite{koza92}, si se desean citar más de uno en el mismo lugar~\cite{bortolot2005, koza92}.


\section{Imágenes}

Se pueden incluir imágenes con los comandos standard de \LaTeX, pero esta plantilla dispone de comandos propios como por ejemplo el siguiente:

\imagen{escudoInfor}{Autómata para una expresión vacía}{.5}



\section{Listas de items}

Existen tres posibilidades:

\begin{itemize}
	\item primer item.
	\item segundo item.
\end{itemize}

\begin{enumerate}
	\item primer item.
	\item segundo item.
\end{enumerate}

\begin{description}
	\item[Primer item] más información sobre el primer item.
	\item[Segundo item] más información sobre el segundo item.
\end{description}
	
\begin{itemize}
\item 
\end{itemize}

\section{Tablas}

Igualmente se pueden usar los comandos específicos de \LaTeX o bien usar alguno de los comandos de la plantilla.

\tablaSmall{Herramientas y tecnologías utilizadas en cada parte del proyecto}{l c c c c}{herramientasportipodeuso}
{ \multicolumn{1}{l}{Herramientas} & App AngularJS & API REST & BD & Memoria \\}{ 
HTML5 & X & & &\\
CSS3 & X & & &\\
BOOTSTRAP & X & & &\\
JavaScript & X & & &\\
AngularJS & X & & &\\
Bower & X & & &\\
PHP & & X & &\\
Karma + Jasmine & X & & &\\
Slim framework & & X & &\\
Idiorm & & X & &\\
Composer & & X & &\\
JSON & X & X & &\\
PhpStorm & X & X & &\\
MySQL & & & X &\\
PhpMyAdmin & & & X &\\
Git + BitBucket & X & X & X & X\\
Mik\TeX{} & & & & X\\
\TeX{}Maker & & & & X\\
Astah & & & & X\\
Balsamiq Mockups & X & & &\\
VersionOne & X & X & X & X\\
} 
