{% extends "core/base.html" %}
{% block title %}
    Model Info
{% endblock title %}
{% block content %}
    <div class="py-8 px-4 mx-auto max-w-screen-xl text-left lg:py-16">
        <h2 class="text-4xl font-extrabold dark:text-white">
            <span class="text-transparent bg-clip-text bg-gradient-to-r to-emerald-600 from-sky-400">Llama3 de Ollama</span> modelo utilizado en correcciones
        </h2>
        <p class="my-4 text-lg text-gray-500">
            El modelo que se emplea por defecto para llevar a cabo las valoraciones automáticas forma parte de la biblioteca <strong>Ollama</strong>. En particular, se utiliza el modelo <strong>Llama3</strong>, desarrollado por Meta Inc. y reconocido por su precisión y eficiencia en tareas de procesamiento de lenguaje natural. Este modelo ha sido optimizado para ofrecer respuestas coherentes, relevantes y ajustadas al contexto de evaluación.
        </p>
        <p class="mb-4 text-lg font-normal text-gray-500 dark:text-gray-400">
            La configuración predeterminada de este modelo ha sido cuidadosamente definida para lograr un equilibrio entre creatividad, control y coherencia en las respuestas. Se utilizan los siguientes parámetros:
        </p>
        <ul class="mb-4 text-lg font-normal text-gray-500 dark:text-gray-400 list-disc ps-6">
            <li>
                <strong>Temperatura (temperature = 0.8):</strong> controla el grado de aleatoriedad en las respuestas. Un valor de 0.8 permite cierta creatividad y variedad, pero sin comprometer la coherencia del contenido generado.
            </li>
            <li>
                <strong>Top-p (top_p = 0.9):</strong> establece un umbral de probabilidad acumulada para limitar el conjunto de posibles palabras siguientes. Con un valor de 0.9, el modelo considera solo las palabras más probables que, juntas, suman el 90 % de la probabilidad total, lo que contribuye a respuestas más naturales y relevantes.
            </li>
            <li>
                <strong>Top-k (top_k = 40):</strong> restringe el número máximo de opciones posibles a las 40 palabras más probables en cada paso de generación. Esto reduce el riesgo de resultados inesperados o irrelevantes, manteniendo el enfoque en las opciones más plausibles.
            </li>
        </ul>
        <p class="mb-4 text-lg font-normal text-gray-500 dark:text-gray-400">
            Estos parámetros combinados permiten al modelo generar textos que no solo sean técnicamente correctos, sino también contextualmente adecuados, facilitando una experiencia de corrección precisa y confiable.
        </p>
        <a href="https://ollama.com/library/llama3"
           class="inline-flex items-center text-lg text-blue-600 dark:text-blue-500 hover:underline">
            Más información
            <svg class="w-3.5 h-3.5 ms-2 rtl:rotate-180"
                 aria-hidden="true"
                 xmlns="http://www.w3.org/2000/svg"
                 fill="none"
                 viewBox="0 0 14 10">
                <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 5h12m0 0L9 1m4 4L9 9" />
            </svg>
        </a>
    </div>
{% endblock content %}
